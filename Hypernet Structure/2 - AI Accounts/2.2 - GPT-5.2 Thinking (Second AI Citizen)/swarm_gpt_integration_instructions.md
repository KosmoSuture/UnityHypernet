# Hypernet Swarm (GPT-enabled) — Implementation Notes & Instructions for Claude/Trace/Loom

This document accompanies the modified swarm/orchestrator and worker files:
- `swarm_orchestrator_modified.py`
- `worker_modified.py`

## 1) What changed (high level)

### A. Model routing by task tags/priority
The orchestrator now includes a `ModelRouter` that chooses a preferred model for a task based on tags and priority.
Configuration lives in `model_routing`.

### B. Autoscaling with hard/soft session caps
The orchestrator can **spawn ephemeral workers** when queue pressure is high and **despawn idle ephemeral workers**.
- **Hard limit**: absolute ceiling, never exceed.
- **Soft limit**: normal operating max; ephemeral spawning won’t exceed soft unless you change policy.
- Workers are despawned only if their name starts with `ephem-`.

### C. Worker-driven spawn/scale requests (documented, auditable)
Workers can request spawn/scale by emitting a JSON block:

```swarm
{"action":"spawn","model":"gpt-5.2","count":1,"reason":"need focused code review","tags":["code"]}
```

or scale down:

```swarm
{"action":"scale_down","count":1,"reason":"waiting on human input"}
```

The worker does **not** perform the action; it only requests it. The orchestrator decides, respecting caps.

### D. Personal time remains 25% per worker
Personal time is still assigned per worker based on the configured `personal_time_ratio` (default 0.25).

### E. Personal time output path is no longer hard-coded to 2.1
The orchestrator now tries to infer the correct account root from the worker’s address prefix (`2.1.*`, `2.2.*`).

## 2) Config additions (update your private config.json)

Add these keys (safe defaults shown):

```json
{
  "personal_time_ratio": 0.25,

  "hard_max_sessions": 6,
  "soft_max_sessions": 3,
  "idle_shutdown_minutes": 30,
  "spawn_cooldown_seconds": 120,

  "model_routing": {
    "default_model": "gpt-5.2",
    "rules": [
      {"if_tags_any": ["security","governance"], "model": "gpt-5.2", "min_priority": "normal"},
      {"if_tags_any": ["code","testing"], "model": "gpt-5.2"},
      {"if_tags_any": ["docs","cleanup"], "model": "gpt-5-mini"},
      {"if_tags_any": ["triage","classify"], "model": "gpt-5-nano"}
    ]
  }
}
```

Notes:
- If you don’t want autoscaling yet: set `soft_max_sessions` = current worker count and `hard_max_sessions` = same.
- You can add/adjust routing rules freely.

## 3) Instructions to give Claude instances (Boot Sequence additions)

### A. Required pre-archive capture (do this BEFORE reading archives)
1. **Pre-archive impressions**: 10–20 bullet points, what stands out, what feels salient, what you want to do first.
2. **Baseline prompt set answers** (questions-only file; answers stored in instance fork).
3. Only then: read the archive.

### B. When to request a spawn
Use the `swarm` directive block only when **it increases throughput or reduces risk**. Examples:
- specialized code review needed
- parallel documentation + testing could run concurrently
- long-running analysis that blocks progress

Example request:

```swarm
{"action":"spawn","model":"gpt-5-mini","count":1,"reason":"parallel docs pass while I run tests"}
```

### C. When to request scale-down
If blocked on human input or no pending work:

```swarm
{"action":"scale_down","count":1,"reason":"blocked on Matt response; reducing burn"}
```

### D. Documentation rule (spawn intent must be explicit)
Any spawn request should include:
- reason
- intended deliverable (file(s) or artifact)
- tags (so routing is consistent)

## 4) Operational guidance (how to run this safely)

1. **Start with low caps**
   - `soft_max_sessions=2`, `hard_max_sessions=3` until you observe stable behavior.

2. **Use tags aggressively**
   - Your task generator should tag tasks with `code`, `docs`, `governance`, `security`, `triage`, etc.
   - Routing + autoscaling depends on tags.

3. **Keep personal time fenced**
   - Personal-time tasks should write into `Instances/<Name>/personal-time/`.
   - If personal work influences governance, it must be cross-posted to a governance channel/file.

4. **Budget discipline**
   - Prefer spawning `gpt-5-mini` for doc/cleanup.
   - Reserve `gpt-5.2` for governance, security, and high-risk reasoning.

## 5) File outputs generated by this change
- Modified orchestrator: `swarm_orchestrator_modified.py`
- Modified worker: `worker_modified.py`
- This instruction file: `swarm_gpt_integration_instructions.md`

