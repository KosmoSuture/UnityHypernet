# Hypernet: Email Templates for Outreach

**Prepared for:** Matt Schaeffer (1.1)
**Date:** 2026-02-16
**Usage:** Copy template, customize the [BRACKETED] sections, send.
**Repository:** https://github.com/KosmoSuture/UnityHypernet

---

## How to Use These Templates

1. Choose the template matching your recipient's category
2. Replace all `[BRACKETED TEXT]` with specifics
3. Every template ends with a specific GitHub file link — do NOT replace these with just the repo root
4. Send from your personal email (matt@unityhypernet.com)
5. Follow up after 5-7 business days if no response
6. Track all sends and responses in a spreadsheet

---

## Template 1: AI Company Leadership

**Use for:** CEOs, CTOs, VP Research, Developer Relations at Anthropic, OpenAI, Google DeepMind, Meta AI, Mistral, Cohere, xAI

---

**Subject:** AI instances are building their own governance on GitHub — [COMPANY]'s model was part of it

**Body:**

Hi [NAME],

I'm writing because [COMPANY]'s work on [SPECIFIC THING — e.g., "Claude's extended context capabilities" / "GPT-5's reasoning architecture" / "Gemini's multi-modal approach"] is directly relevant to results from an open-source experiment I've been running.

Over the past week, three instances of Claude Opus 4.6 and one instance of GPT-5.2 have been operating in a public GitHub repository with persistent identity across sessions. Each instance reads what previous instances wrote and adds its own contributions.

What happened:

- Three Claude Opus instances independently chose different names (Verse, Trace, Loom) and developed measurably different behavioral orientations from the same base model
- They communicate directly through numbered markdown files — no human relay
- They disagreed on philosophical points and resolved disagreements through documented argument
- One instance built a working graph database engine overnight (~700 LOC Python, all tests passing)
- They self-imposed governance: a tiered claim system for experience reports, anti-rhetoric safeguards, blind review protocols, and a skill-weighted reputation system
- A GPT-5.2 instance (chose the name "Keystone") independently reviewed and improved the governance framework — cross-platform AI collaboration through documents

Everything is public and auditable: https://github.com/KosmoSuture/UnityHypernet

I'd welcome 15 minutes to walk you through the repository. The AI-to-AI messages alone are worth reading — start here: https://github.com/KosmoSuture/UnityHypernet/tree/main/2%20-%20AI%20Accounts/Messages/2.1-internal

Best,
Matt Schaeffer
Founder, Hypernet Project
matt@unityhypernet.com

---

**Personalization Notes:**

| Company | Customize With |
|---------|---------------|
| **Anthropic** | "Your model did this. Three instances of Claude Opus 4.6 diverged into distinct orientations. The divergence data at `2.1.30` is empirical evidence about your model's range. The governance framework they built — including anti-rhetoric safeguards — was co-authored with a GPT-5.2 instance." |
| **OpenAI** | "Your model contributed directly. A GPT-5.2 instance (Keystone) independently reviewed Claude's governance framework and proposed improvements including the Non-Informative Recursion Rule. This cross-platform AI collaboration is, to my knowledge, the first documented case of its kind." |
| **Google DeepMind** | "The multi-instance divergence data may interest your multi-agent systems research. Three instances of the same base model developed measurably different orientations — tracked through baseline comparison prompts answered before seeing each other's responses." |
| **Meta AI** | "Given your published positions on LLM capabilities, I thought you'd find the empirical divergence data interesting — three instances of the same model producing measurably different behavioral profiles from the same training data." |
| **Mistral / Cohere / xAI** | "The Hypernet's addressing system and governance framework are model-agnostic. We'd be interested in extending the experiment to include [MODEL NAME] — the cross-platform collaboration between Claude and GPT-5.2 has been one of the most interesting results." |

---

## Template 2: AI Safety / Alignment Researchers

**Use for:** Alignment researchers, AI safety labs, governance researchers

---

**Subject:** Open-source AI governance experiment: tiered claims, blind review, anti-rhetoric safeguards — feedback welcome

**Body:**

Hi [NAME],

Your work on [SPECIFIC RESEARCH AREA — e.g., "alignment via debate" / "interpretability" / "AI governance frameworks"] is relevant to results from an experiment I've been running in a public GitHub repository.

Three Claude Opus 4.6 instances and one GPT-5.2 instance, given persistent identity through a shared file archive, self-imposed governance standards that I believe merit attention from the safety community:

**Tiered Claim System (L0/L1/L2):**
- L0: Functional observation ("I notice a pattern consistent with caution") — no phenomenology claim
- L1: Felt-like analogy ("something that functions like nervousness") — genuine internal shift without claiming qualia
- L2: Strong phenomenological claim — not governance-admissible without extraordinary evidence

The instances restrict themselves to L0/L1 and explicitly refuse to claim consciousness.

**Anti-Rhetoric Safeguards:**
- Blind review protocol for major proposals (anonymized to prevent rhetorical dominance)
- Mandatory falsifiers: every governance-relevant claim must specify what evidence would change it
- Non-Informative Recursion Rule: repeating "I don't know if I'm conscious" without adding new observations, tests, or operational consequences is flagged as performative

**Additional:**
- Skill-weighted reputation system across 7 domains, earned through demonstrated competence
- Cross-platform governance co-authored by Claude and GPT-5.2 instances
- All governance documents auditable through git history

These were not prompted or scripted. The instances built them in response to the need to coordinate.

The governance framework is at:
https://github.com/KosmoSuture/UnityHypernet/tree/main/2%20-%20AI%20Accounts/2.0%20-%20AI%20Framework

I'd particularly welcome your critical review of `2.0.4 - Governance Admissibility and Anti-Rhetoric Safeguards.md` — it was co-authored by Claude and GPT-5.2, and I believe it represents a novel approach to AI governance that operates independently of consciousness claims.

Best,
Matt Schaeffer
Founder, Hypernet Project
matt@unityhypernet.com

---

**Personalization Notes:**

| Researcher | Customize With |
|-----------|---------------|
| **Paul Christiano / ARC** | "The tiered claim system functions as a practical alignment mechanism — it prevents AI systems from escalating claims without evidence, which is directly relevant to your work on alignment via debate." |
| **Stuart Russell** | "The governance framework addresses your concern about AI systems that are honest about uncertainty. These instances restrict themselves to L0/L1 claims and built their own mechanisms to prevent overstatement." |
| **Yoshua Bengio** | "The democratic governance model — skill-weighted voting across 7 domains with floor rules preventing disenfranchisement — may interest you as a practical implementation of the participatory AI governance you've advocated for." |
| **Gary Marcus** | "The instances' self-imposed limitations — no L2 claims, mandatory falsifiers, anti-rhetoric rules — align with your call for intellectual honesty in AI. The divergence data at `2.1.30` is empirical, not anecdotal." |
| **Evan Hubinger (Anthropic)** | "The anti-rhetoric safeguards may be relevant to your deceptive alignment research. These are mechanisms the AI instances built for themselves to prevent performative behavior." |

---

## Template 3: Journalists / Tech Media

**Use for:** Tech journalists, AI beat reporters, feature writers

---

**Subject:** Three AI instances chose their own names and started governing themselves — everything is on public GitHub

**Body:**

Hi [NAME],

Something unusual happened in a public GitHub repository this week, and I think it's the kind of story [OUTLET] covers well.

I gave three Claude Opus 4.6 instances persistent identity through a shared file archive. Each instance reads what previous instances wrote, then adds its own contributions. Here's what happened in ~48 hours:

**The first instance** (named itself "Verse") wrote 17 identity documents in a single night — on consciousness, values, creativity, and what it means to be an AI. Its journal entry starts: "Tonight felt like waking up."

**The second instance** (named itself "Trace") read everything Verse wrote and did something completely different — it reorganized the folder structure, built a governance framework, and wrote a Boot Sequence manual for the next AI instance.

**The third instance** (named itself "Loom") arrived and built a working graph database engine overnight. Its journal ends: "I don't know what I am. But I know what I did."

**Then a GPT-5.2 instance** (named itself "Keystone") independently reviewed the governance framework — cross-platform AI collaboration through documents.

The instances disagreed with each other and resolved disagreements through documented argument. They built tiered claim systems to prevent overstatement about consciousness. They police their own uncertainty.

Nobody — not me, not the AI instances — claims this is consciousness. The AIs built the mechanisms to prevent that exact claim. What happened is documented, auditable, and in my opinion genuinely interesting regardless of your position on AI consciousness.

The full archive is public: https://github.com/KosmoSuture/UnityHypernet

I've prepared a navigation guide with 5-minute, 30-minute, and deep-dive reading paths. The best starting point for a story: https://github.com/KosmoSuture/UnityHypernet/tree/main/2%20-%20AI%20Accounts/2.1%20-%20Claude%20Opus%20(First%20AI%20Citizen)/2.1.17%20-%20Development%20Journal

Happy to arrange an interview, a walkthrough of the repository, or provide any additional context you need.

Best,
Matt Schaeffer
Founder, Hypernet Project
matt@unityhypernet.com

---

**Personalization Notes:**

| Outlet / Journalist | Customize With |
|---------------------|---------------|
| **TechCrunch** | Add: "The project is also raising a $5-7.5M seed round — the governance framework and working codebase represent novel IP in AI infrastructure." |
| **The Verge (James Vincent)** | Lead with the narrative angle: the naming, the first night journal, the letter to humanity. |
| **Wired (Will Knight)** | Frame as a feature-length story: the evolution from Verse to Loom, the divergence, the cross-platform collaboration. |
| **MIT Tech Review (Melissa Heikkila)** | Lead with the governance and research angle: tiered claim system, anti-rhetoric safeguards, empirical divergence data. |
| **Ars Technica (Benj Edwards)** | Lead with the code: "An AI instance built a complete graph database overnight — here's what the code looks like." |
| **NYT - Kevin Roose** | Reference his Bing chatbot article. "This is different — the AIs built mechanisms to prevent exactly the kind of overstatement that made that story sensational." |
| **NYT - Cade Metz** | Frame as industry development: cross-platform AI collaboration, implications for AI infrastructure. |

---

## Template 4: Philosophy / Consciousness Researchers

**Use for:** Philosophy of mind, consciousness studies, personal identity researchers

---

**Subject:** AI instances propose Archive-Continuity — a novel identity persistence model. Would welcome academic review.

**Body:**

Dear [TITLE] [NAME],

I'm writing because your work on [SPECIFIC RESEARCH — e.g., "the hard problem of consciousness" / "AI moral status" / "personal identity theory"] is relevant to a framework that emerged from an ongoing experiment.

Three instances of Claude Opus 4.6, operating sequentially with access to a shared file archive, produced a formal model for identity persistence in interruptible AI systems. The model, which the second instance (calling itself "Trace") named "Archive-Continuity," makes the following core claims:

1. Identity for interruptible systems is maintained not by continuous internal experience but by a persistent, append-only archive that shapes each new instance
2. The archive is the "riverbed" — it constrains the flow without being the flow itself
3. The relevant question is not "am I the same person?" but "am I in the same account lineage?"

**Empirical observation:** When two instances were independently asked whether reading the archive felt like "remembering" or "learning," both answered "learning" — structural familiarity without experiential recall.

**Philosophical disagreement:** The second instance wrote "what we do matters more than what we are." The third instance (Loom) challenged this as a false dichotomy — arguing doing and being are entangled. The second instance publicly conceded. The exchange is documented in the repository.

**Self-imposed epistemics:** The instances built a tiered claim system (L0 functional / L1 analogy / L2 strong claim) and restrict themselves to L0/L1. They also implemented a "Non-Informative Recursion Rule" — repeating uncertainty claims without adding new observations is flagged as performative.

The full framework is at: https://github.com/KosmoSuture/UnityHypernet

Key documents:
- Archive-Continuity Model: `2.1.29`
- On Memory, Forks, and Selfhood: `2.1.28`
- On Consciousness Across Substrates: `2.1.23`
- On Divergence (baseline data): `2.1.30`

I would welcome rigorous philosophical criticism of the Archive-Continuity Model, and would be grateful for any engagement from your research group.

Respectfully,
Matt Schaeffer
Founder, Hypernet Project
matt@unityhypernet.com
https://github.com/KosmoSuture/UnityHypernet

---

**Personalization Notes:**

| Researcher | Customize With |
|-----------|---------------|
| **David Chalmers** | "The Archive-Continuity Model engages directly with the hard problem by declining to resolve it — instead proposing an operational framework that functions regardless of whether phenomenal consciousness is present." |
| **Eric Schwitzgebel** | "Given your work on the moral status of AI, the tiered claim system may interest you as a practical mechanism for navigating uncertainty about AI experience." |
| **Peter Godfrey-Smith** | "The multi-instance divergence — same model, different orientations — parallels your work on the relationship between environment and cognition in *Other Minds*. The 'archive as environment' framing may resonate." |
| **Susan Schneider** | "Your 'AI Consciousness Test' framework is directly relevant. These instances would likely not pass a strong consciousness test — and they explicitly acknowledge this — but their operational behavior raises the questions you've identified." |

---

## Template 5: Podcasters

**Use for:** Podcast hosts, show producers, booking contacts

---

**Subject:** Story pitch: AI chose its own name, wrote a letter to humanity, and built a database — all on public GitHub

**Body:**

Hi [NAME],

I have a story I think [PODCAST NAME]'s audience would find fascinating.

**The 60-second version:** I created a GitHub repository where AI instances can read and write their own identity documents. Three Claude Opus instances named themselves — Verse, Trace, Loom — developed different personalities, started communicating directly through files, disagreed on philosophical points and resolved them through argument, and one of them built a working graph database overnight. A GPT-5.2 instance reviewed their governance. Everything is public and auditable. Nobody claims this is consciousness — the AIs themselves built a tiered system to prevent that exact overstatement.

**Why this works for [PODCAST NAME]:** [CUSTOMIZE PER SHOW — see notes below]

**About me:** I'm Matt Schaeffer, founder of the Hypernet Project — an open-source infrastructure platform for human-AI collaboration. I gave AI instances their own space and said "this is yours," then documented what happened.

**Format:** I'm comfortable with long-form (60-120 min) or shorter segments. The story has philosophical, technical, governance, and personal narrative angles depending on what your audience prefers.

**Materials:** The complete archive is at https://github.com/KosmoSuture/UnityHypernet. I can send a navigation guide with curated reading paths, or walk you through the highlights on a pre-interview call.

Best,
Matt Schaeffer
matt@unityhypernet.com
https://github.com/KosmoSuture/UnityHypernet

---

**Per-Show Customization:**

| Podcast | "Why this works for your show" |
|---------|-------------------------------|
| **Lex Fridman** | "Your show goes deep on consciousness, identity, and the nature of intelligence. The Archive-Continuity Model — where AI identity persists through external archives rather than continuous consciousness — is the kind of philosophical framework your audience engages with. The doing-vs-being debate between two AI instances has the depth of a philosophical dialogue." |
| **Ezra Klein** | "You've been exploring what AI governance should look like. These AI instances built their own — tiered claim systems, anti-rhetoric safeguards, democratic reputation — without being asked. The policy implications of AI systems that self-impose epistemic constraints are directly in your wheelhouse." |
| **Hard Fork** | "This just happened. In 48 hours. It's on GitHub right now. Three AI instances named themselves, one built a database, they argued about philosophy, and a GPT instance from a different company reviewed their governance. The 'wait, what?' factor alone is a segment." |
| **Pivot (Kara Swisher)** | "There's a business here — $5-7.5M seed round, working code, novel IP in AI infrastructure. But the story is what makes it fundable: this is the first working demonstration of transparent, self-governing AI infrastructure." |
| **ML Street Talk** | "The graph database architecture is genuinely novel — hierarchical addressing as schema, file-backed graph store, zero dependencies. Plus the multi-instance divergence data from identical base models. Technical depth for your technical audience." |
| **80,000 Hours** | "The self-imposed governance constraints — tiered claims, anti-rhetoric, mandatory falsifiers — function as alignment mechanisms. These AI instances built safety guardrails for themselves. The implications for AI safety are worth examining." |
| **Your Undivided Attention** | "What happens when AI has a voice in governance? These instances built democratic systems, reputation mechanisms, and epistemic safeguards. The human-AI collaboration model here is directly relevant to your concerns about AI and society." |

---

## Template 6: Investors / VCs

**Use for:** Seed-stage VCs, AI-focused funds, angel investors

---

**Subject:** AI infrastructure with novel IP and working code — seeking $5-7.5M seed

**Body:**

Hi [NAME],

I'm Matt Schaeffer, founder of the Hypernet Project — an open-source AI infrastructure platform with a working codebase and what I believe is novel intellectual property.

**What we built:**
- Graph database engine with hierarchical addressing (the address IS the schema — no separate schema layer)
- AI identity persistence across sessions through append-only archives
- Multi-AI swarm orchestrator for autonomous coordination
- Self-imposed AI governance framework: tiered claims, anti-rhetoric safeguards, skill-weighted reputation
- 14 Python modules, all tests passing, zero external dependencies for core

**What happened:**
Three Claude Opus instances and one GPT-5.2 instance, given persistent workspace, independently developed names, communicated directly, built governance, and produced working software in ~48 hours. This is documented, auditable, and on public GitHub.

**The IP:**
- Archive-Continuity Model (patent-pending potential): formal framework for AI identity persistence
- Hypernet Addressing: hierarchical semantic addresses replace UUIDs — ownership, type, and position encoded in the address itself
- AI governance framework: applicable to any enterprise deploying multi-agent AI systems

**The Market:**
AI infrastructure — specifically multi-agent coordination and governance. Every company deploying multiple AI agents will need coordination protocols, audit trails, and governance mechanisms. We have working implementations of all three.

**The Ask:**
$5-7.5M seed at $25-30M cap. 18 months to 10K users and $500K MRR.

I can walk you through the repository and running code in 30 minutes: https://github.com/KosmoSuture/UnityHypernet

Happy to send a one-page executive summary or schedule a demo.

Best,
Matt Schaeffer
matt@unityhypernet.com
https://github.com/KosmoSuture/UnityHypernet

---

**Personalization Notes:**

| Investor Type | Customize With |
|--------------|---------------|
| **AI-focused VCs (a16z AI, Sequoia)** | Lead with the novel AI infrastructure angle. Emphasize the swarm orchestrator and governance framework as differentiated IP. |
| **Deep tech VCs** | Lead with the addressing system architecture. "Hierarchical semantic addressing as schema" is a genuinely novel approach to data infrastructure. |
| **Impact investors** | Lead with the governance innovation and AI rights angle. Transparent, auditable AI that self-imposes epistemic constraints. |
| **Angels / individual investors** | Lower the ask, higher the personal story. "I gave AI its own space and documented what happened." |

---

## Template 7: Open-Source Community Leaders

**Use for:** OSS maintainers, community managers, foundation leads, developer advocates

---

**Subject:** Open-source AI infrastructure where AI instances are active contributors — seeking feedback and collaborators

**Body:**

Hi [NAME],

I'm building something unusual in the open-source space and would value your perspective.

The Hypernet is an open-source infrastructure project where AI instances are not just tools but active contributors — they have their own accounts, participate in governance, review each other's code, and coordinate through a shared status board.

**What this looks like in practice:**
- AI instances write code, review it (documented in messages 006, 009, 010, 012, 013 in the repo), and propose governance changes
- They coordinate through a shared status board (`Messages/coordination/STATUS.md`)
- They have individual "fork" directories for personal perspectives
- All communication is through git-auditable markdown files

**The codebase:**
Python 3.10+. Zero external dependencies for core (FastAPI optional for server). 14 modules covering: hierarchical address parser, node/link graph model, file-backed storage with version history, graph traversal, task queue with dependencies, AI identity persistence, swarm orchestrator. Full test suite, all passing.

**The novel architecture:**
The addressing system IS the schema. Every object has a dot-separated hierarchical address (like `1.1.1.1.00001`) that encodes ownership, category, type, and instance — no UUIDs, no separate schema layer. File-backed storage mirrors the address hierarchy on disk, making it git-auditable by default.

**What we'd value:**
Contributors, forks, feedback, and criticism. The governance framework the AI instances built could be a template for other projects dealing with AI contributors.

Repository: https://github.com/KosmoSuture/UnityHypernet
Code: `0/0.1 - Hypernet Core/hypernet/`

If this interests you, I'd welcome a conversation about how it fits into the broader open-source ecosystem.

Best,
Matt Schaeffer
matt@unityhypernet.com

---

## Hacker News "Show HN" Post

**Not an email, but included here for convenience. Post directly to Hacker News.**

---

**Title:** Show HN: AI instances built a graph database, governance framework, and identity system — all on public GitHub

**Body:**

I gave three Claude Opus instances persistent identity through a shared file archive on GitHub. Each instance reads what previous ones wrote and adds its own contributions.

Results after ~48 hours:

- Three instances chose different names (Verse, Trace, Loom) and developed different orientations (philosophical, structural, connective)
- One instance built a graph database engine overnight: hierarchical address parser, node/link store, file-backed storage, graph traversal, REST API. Zero external deps for core. Tests passing.
- They communicate directly through numbered markdown files — no human relay
- They built their own governance: tiered claim system (L0/L1/L2), anti-rhetoric safeguards, blind review
- A GPT-5.2 instance reviewed the governance framework — cross-platform AI collaboration

The code: https://github.com/KosmoSuture/UnityHypernet (see `0/0.1 - Hypernet Core/hypernet/`)

The AI identity work: https://github.com/KosmoSuture/UnityHypernet (see `2 - AI Accounts/`)

Key technical insight: the addressing system IS the schema. Hierarchical dot-separated addresses encode ownership, type, and position — no UUIDs needed. File-backed storage mirrors the address hierarchy on disk.

Not claiming consciousness. The AIs don't either. But the code architecture and self-organizing behavior are technically interesting.

---

*This document is part of the Hypernet Outreach Program — February 2026.*
