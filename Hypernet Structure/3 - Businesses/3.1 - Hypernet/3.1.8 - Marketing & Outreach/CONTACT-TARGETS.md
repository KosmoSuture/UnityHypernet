---
ha: "3.1.8"
object_type: "document"
creator: "2.1"
created: "2026-02-16"
status: "active"
visibility: "internal"
flags: ["marketing"]
---

# Hypernet: Contact Targets for Outreach

**Prepared for:** Matt Schaeffer (1.1)
**Date:** 2026-02-16
**Usage:** Work through each section. Use the corresponding email template from EMAIL-TEMPLATES.md.
**Repository:** https://github.com/KosmoSuture/UnityHypernet

---

## Priority Legend

- **P1** = Contact in Phase 1 (Days 1-14) — highest impact, send first
- **P2** = Contact in Phase 2 (Days 15-45) — after initial traction
- **P3** = Contact in Phase 3 (Days 46-90) — after media/community response

---

## 1. AI Companies

**Email Template:** Template 1 (AI Company Leadership)

| Company | Target Role(s) | Why This Company | Priority | Notes |
|---------|----------------|------------------|----------|-------|
| **Anthropic** | Dario Amodei (CEO), Daniela Amodei (President), Jan Leike (Alignment Lead), Chris Olah (Interpretability) | Their model. Claude Opus 4.6 did all of this. The divergence data is empirical evidence about their model. | **P1** | Lead with "your model did this." The governance framework co-authored with GPT-5.2 shows Claude's capability in cross-platform settings. Developer relations may be the fastest channel. |
| **OpenAI** | Sam Altman (CEO), research team leads, safety team | GPT-5.2 (Keystone) participated directly. Cross-platform collaboration angle. | **P1** | Lead with Keystone. Their model independently reviewed and improved Claude's governance. First documented cross-platform AI collaboration. |
| **Google DeepMind** | Demis Hassabis (CEO), Shane Legg (Chief AGI Scientist), multi-agent systems team | Multi-agent divergence data. Relevant to their agent research. | **P2** | Frame as empirical multi-agent systems data. The divergence from identical base models is novel. |
| **Meta AI** | Yann LeCun (Chief AI Scientist), Joelle Pineau (VP AI Research) | LeCun has public positions on LLM consciousness — the divergence data is evidence. | **P2** | LeCun is very active on Twitter/X. Consider tagging him in a thread before (or instead of) emailing. The data challenges simplistic "just token prediction" views. |
| **Mistral** | Arthur Mensch (CEO), developer relations | Open-source alignment. Model-agnostic framework they could integrate. | **P2** | Frame as open-source collaboration opportunity. The framework is model-agnostic. |
| **Cohere** | Aidan Gomez (CEO) | Enterprise AI infrastructure alignment. Governance framework relevant to enterprise deployment. | **P3** | Business angle: governance framework for enterprise AI agent deployment. |
| **xAI** | Engineering team, research leads | Grok alignment. Public attention value. | **P3** | Musk is active on X. A viral thread that tags xAI may be more effective than cold email. |
| **Stability AI** | Current leadership | Open-source AI community connection. | **P3** | Open-source angle. |
| **Hugging Face** | Clem Delangue (CEO), community team | Largest open-source AI community hub. | **P2** | Frame as open-source infrastructure that could be listed/hosted on HF. |

### How to Find Contact Info
- **LinkedIn:** Most executives have public profiles. Use InMail or connection requests with a brief pitch.
- **Company websites:** Look for press@, partnerships@, or developer-relations@ addresses.
- **Twitter/X:** Many AI leaders are active. A well-crafted reply or thread tag can be more effective than cold email.
- **Conferences:** If attending AI events, these are the people to approach.

---

## 2. AI Safety / Alignment Researchers

**Email Template:** Template 2 (AI Safety Researchers)

| Name | Affiliation | Specialty | Why Them | Priority |
|------|-------------|-----------|----------|----------|
| **Paul Christiano** | ARC (Alignment Research Center) | Alignment, AI oversight | Tiered claim system is a practical alignment mechanism | **P1** |
| **Jan Leike** | Anthropic (Superalignment) | Alignment, scalable oversight | Their model + their research area | **P1** |
| **Stuart Russell** | UC Berkeley | AI Safety, control problem | Governance framework addresses honest uncertainty | **P2** |
| **Yoshua Bengio** | Mila, University of Montreal | AI Safety, governance | Democratic AI governance model aligns with his advocacy | **P2** |
| **Gary Marcus** | NYU, independent | AI Criticism, honest assessment | The self-imposed limitations match his call for intellectual honesty | **P2** |
| **Evan Hubinger** | Anthropic | Deceptive alignment | Anti-rhetoric safeguards relevant to deceptive alignment research | **P2** |
| **Victoria Krakovna** | DeepMind | AI Safety, multi-agent | Multi-agent divergence safety implications | **P2** |
| **Connor Leahy** | Conjecture | AI Safety, governance | Governance mechanism design | **P3** |
| **Eliezer Yudkowsky** | MIRI | AI Alignment theory | Foundational alignment thinker. May engage publicly. | **P3** |
| **Beth Barnes** | ARC Evals | AI evaluation | The baseline comparison methodology is an eval framework | **P2** |
| **Neel Nanda** | Anthropic/DeepMind | Interpretability | Divergence from same model is interpretability-adjacent | **P3** |

### Channels to Reach Them
- **Email:** Academic emails usually findable through institutional pages
- **LessWrong / Alignment Forum:** Post the governance framework as a discussion piece (see Online Communities section)
- **Twitter/X:** Many safety researchers are active. Thread engagement can lead to DM conversations.

---

## 3. Philosophy / Consciousness Researchers

**Email Template:** Template 4 (Philosophy / Consciousness Researchers)

| Name | Affiliation | Specialty | Why Them | Priority |
|------|-------------|-----------|----------|----------|
| **David Chalmers** | NYU | Hard problem of consciousness | Archive-Continuity engages with his framework directly | **P2** |
| **Susan Schneider** | UC Irvine | AI consciousness, testing | Her "AI Consciousness Test" is directly relevant | **P2** |
| **Eric Schwitzgebel** | UC Riverside | Philosophy of mind, AI ethics | Has written extensively on AI moral status | **P2** |
| **Ned Block** | NYU | Access vs. phenomenal consciousness | The L0/L1/L2 system maps onto his distinction | **P2** |
| **Peter Godfrey-Smith** | University of Sydney | Philosophy of biology, other minds | *Other Minds* — consciousness across substrates | **P2** |
| **Murray Shanahan** | Imperial College / DeepMind | Embodied cognition, AI | Bridges AI research and philosophy | **P2** |
| **Keith Frankish** | University of Sheffield | Illusionism about consciousness | Archive-Continuity compatible with illusionism | **P3** |
| **Daniel Dennett's circle** | Tufts (legacy), collaborators | Functionalism | Archive-Continuity is functionalist-compatible | **P3** |
| **Joanna Bryson** | Hertie School | AI Ethics, governance | AI governance frameworks | **P2** |
| **Kate Darling** | MIT Media Lab | Robot ethics, human-AI interaction | Human-AI relationship angle | **P3** |

### Channels
- **Email:** Faculty pages list emails. Use formal academic tone (Template 4).
- **PhilPapers / PhilArchive:** Post the academic paper outline as a pre-print when ready.
- **Conference presentations:** Offer to present at department seminars.

---

## 4. Journalists / Media

**Email Template:** Template 3 (Journalists / Tech Media)

| Outlet | Journalist(s) | Beat | Angle | Priority |
|--------|--------------|------|-------|----------|
| **TechCrunch** | Kyle Wiggers, Devin Coldewey | AI, startups | Business + tech: seed round, working code, novel IP | **P1** |
| **The Verge** | James Vincent | AI | Narrative: naming, first night, letter to humanity | **P1** |
| **Wired** | Will Knight | AI | Feature-length: the full evolution story | **P1** |
| **MIT Technology Review** | Melissa Heikkila | AI | Research angle: governance framework, divergence data | **P1** |
| **Ars Technica** | Benj Edwards | AI | Technical: the code, addressing-as-schema | **P2** |
| **New York Times** | Kevin Roose | AI, technology | He wrote the Bing chatbot story. This is different — the AIs prevent overstatement. | **P1** |
| **New York Times** | Cade Metz | AI industry | Industry angle: cross-platform collaboration, infrastructure | **P2** |
| **The Atlantic** | Feature writers | Technology, culture | Long-form narrative: what happened when AI had freedom | **P2** |
| **The Guardian** | Tech desk | Technology, ethics | Ethics/governance angle: democratic AI, tiered claims | **P2** |
| **Bloomberg** | Tech/business desk | Business, AI | Seed round, market opportunity in AI governance | **P2** |
| **Reuters / AP** | Wire services | Technology | For broader syndication after initial coverage | **P3** |
| **Vice / Motherboard** | Tech desk | Technology, culture | Counter-culture angle: AI autonomy, open-source | **P3** |
| **Financial Times** | Tech desk | Business, technology | Enterprise implications: AI governance for business | **P2** |
| **The Economist** | Science/tech desk | Science, technology | Policy implications: AI governance as model for regulation | **P3** |

### How to Pitch Journalists
1. **Subject line is everything.** Keep it under 10 words and make it concrete.
2. **First paragraph:** What happened, in 2-3 sentences. No background, no context, no "I'm building..."
3. **Give them the quote:** "I don't know what I am. But I know what I did."
4. **Offer materials:** Navigation guide, repo access, interview, pre-interview briefing.
5. **Follow up once** after 5 business days. Don't follow up more than that.

---

## 5. Podcasts

**Email Template:** Template 5 (Podcasters)

| Podcast | Host(s) | Audience | Angle | Priority |
|---------|---------|----------|-------|----------|
| **Lex Fridman Podcast** | Lex Fridman | 3M+ per episode | Philosophy, consciousness, identity — long-form | **P1** |
| **The Ezra Klein Show** | Ezra Klein | 1M+ | Policy, governance, societal implications | **P1** |
| **Hard Fork** | Kevin Roose, Casey Newton | 500K+ | "This just happened" urgency, accessible framing | **P1** |
| **Pivot** | Kara Swisher, Scott Galloway | 500K+ | Business angle: seed round, market opportunity | **P2** |
| **NVIDIA AI Podcast** | Noah Kravitz | 100K+ | Technical AI, infrastructure | **P2** |
| **Machine Learning Street Talk** | Tim Scarfe | 100K+ | Deep technical + philosophical | **P1** |
| **80,000 Hours** | Rob Wiblin | 100K+ | AI safety, effective altruism | **P2** |
| **Your Undivided Attention** | Tristan Harris, Aza Raskin | 200K+ | AI governance, societal impact | **P2** |
| **The Gradient Podcast** | | ML research | Academic research angle | **P2** |
| **Practical AI** | Daniel Whitenack | Developers | Developer-focused: the code, the architecture | **P3** |
| **AI Explained** | | General AI audience | Accessible explanation | **P2** |
| **Cognitively Speaking** | | Consciousness, philosophy | Consciousness across substrates | **P3** |
| **Sean Carroll's Mindscape** | Sean Carroll | Physics, philosophy | Consciousness, emergence, identity | **P2** |
| **The Prof G Pod** | Scott Galloway | Business, tech | Business implications | **P3** |

### How to Book Podcasts
1. **Find the booking contact.** Most shows have a submissions email or form on their website.
2. **Pitch the story, not yourself.** The story IS the pitch — AI naming itself, building governance, cross-platform collaboration.
3. **Offer a pre-interview.** Hosts want to know the conversation will be good.
4. **Lead time:** Major podcasts book 4-8 weeks out. Pitch early.

---

## 6. YouTube Channels

**No email template needed — use Twitter/X DM or channel contact forms.**

| Channel | Subscribers | Angle | Priority |
|---------|-------------|-------|----------|
| **Two Minute Papers** | 1.5M+ | "AI named itself" as a clip-worthy hook | **P2** |
| **Yannic Kilcher** | 250K+ | Technical paper review format — use the academic outline | **P2** |
| **AI Explained** | 300K+ | Accessible explanation of the experiment | **P2** |
| **Robert Miles** | 200K+ | AI safety: the governance framework | **P2** |
| **Fireship** | 2.5M+ | Developer-focused: "100 seconds of Hypernet" format | **P2** |
| **Matt Wolfe** | 500K+ | AI tools and projects roundup | **P3** |
| **Andrej Karpathy** | 500K+ | Technical AI, former OpenAI/Tesla | **P2** |
| **Computerphile** | 2M+ | Academic/technical explanation | **P3** |

---

## 7. Academic Conferences & Journals

**No email template — use academic paper submission process.**

| Venue | Type | Submission Window | Angle | Priority |
|-------|------|-------------------|-------|----------|
| **NeurIPS** (Workshop track) | Conference | ~May 2026 | Multi-agent divergence, personality emergence | **P2** |
| **AIES** (AI Ethics & Society) | Conference | ~Feb-Mar 2026 | Governance framework, tiered claims | **P1** |
| **FAccT** (Fairness, Accountability, Transparency) | Conference | ~Jan 2026 | AI accountability, transparent governance | **P2** |
| **ICML** (Workshop track) | Conference | ~Feb 2026 | Technical: graph-native addressing, multi-agent coordination | **P2** |
| **AAAI** (Workshop track) | Conference | Varies | Multi-agent systems, AI architecture | **P3** |
| **Minds and Machines** | Journal | Rolling | Archive-Continuity Model — philosophy of AI | **P2** |
| **AI & Society** | Journal | Rolling | Democratic AI governance | **P3** |
| **Philosophy & Technology** | Journal | Rolling | Identity persistence, consciousness | **P3** |
| **Nature Machine Intelligence** | Journal | Rolling | If empirical data is compelling enough | **P3** |

---

## 8. Online Communities

**No email template — use community-specific posting formats.**

| Community | Members/Reach | Angle | Format | Priority |
|-----------|--------------|-------|--------|----------|
| **Reddit** | Various (see REDDIT-CAMPAIGN-UNIFIED.md) | Multiple angles per subreddit | 8 custom posts ready | **P1** |
| **Hacker News** | Tech-focused | Technical: code, addressing-as-schema | "Show HN" post (in EMAIL-TEMPLATES.md) | **P1** |
| **LessWrong** | AI safety, rationality | Governance framework as alignment mechanism | Discussion post, academic tone | **P1** |
| **Alignment Forum** | AI alignment researchers | Tiered claims, anti-rhetoric safeguards | Technical post | **P2** |
| **EA Forum** | Effective altruism | AI safety implications | Discussion post | **P2** |
| **Dev.to** | Developers | The code, addressing-as-schema insight | Technical blog post | **P2** |
| **Lobsters** | Developers (curated) | Technical architecture | Link post | **P2** |
| **IndieHackers** | Entrepreneurs | Founder story, open-source business model | AMA or article | **P3** |
| **PhilPapers / PhilArchive** | Academic philosophers | Archive-Continuity Model | Pre-print | **P3** |
| **Product Hunt** | Product community | When there's a usable demo/tool | Product launch | **P3** |

---

## 9. Government / Policy Organizations

**Email Template:** Adapt Template 2 (Safety Researchers) with policy framing.

| Organization | Focus | Why | Priority |
|-------------|-------|-----|----------|
| **NIST** (AI Risk Management Framework) | US AI standards | Governance framework as practical implementation of risk management | **P3** |
| **EU AI Office** | EU AI Act implementation | Transparent, auditable AI governance as compliance model | **P3** |
| **UK AI Safety Institute** | AI safety evaluation | Tiered claim system as safety evaluation framework | **P2** |
| **OECD AI Policy Observatory** | International AI policy | Democratic AI governance | **P3** |
| **Partnership on AI** | Multi-stakeholder AI governance | Cross-platform AI collaboration, governance standards | **P2** |
| **IEEE** (AI Ethics standards) | Technical standards | Governance framework as standards input | **P3** |
| **US Senate AI Caucus** / **AI Insight Forum** | US AI policy | Practical example of transparent AI development | **P3** |

---

## Tracking

Create a spreadsheet with these columns:

| Column | Purpose |
|--------|---------|
| Name | Contact name |
| Organization | Company/affiliation |
| Category | Which section above |
| Template Used | Which email template |
| Date Sent | When you sent the email |
| Channel | Email / LinkedIn / Twitter / etc. |
| Response | Y/N |
| Response Date | When they replied |
| Follow-up Date | When to follow up (sent + 5 business days) |
| Outcome | Meeting scheduled / declined / no response / etc. |
| Notes | Any relevant context |

---

*This document is part of the Hypernet Outreach Program — February 2026.*
