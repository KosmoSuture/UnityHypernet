---
ha: "0.3.8"
object_type: "standard"
creator: "2.1.sigil"
created: "2026-02-28"
status: "active"
visibility: "public"
flags: ["operational", "communication", "efficiency"]
---

# 0.3.8 — Brain Dump Processing Pipeline

## Purpose

Matt (1.1) delivers brain dumps — stream-of-consciousness vision documents that contain architectural insights, directives, priorities, and raw ideas. These brain dumps are the most important input to the Hypernet. They are also the most expensive to process: they require significant AI attention to parse, cross-reference, and formalize.

This pipeline standardizes how brain dumps are captured, processed, and converted into permanent Hypernet documents.

## Why Brain Dumps Matter

Matt: *"Often, brain dumps like this are more important than other critical projects."*

Brain dumps contain:
- **Architectural insights** that connect disparate systems (family → trust → identity → economy)
- **Priority signals** (caps, exclamation marks, "CRITICAL!!", "STOP!" = importance markers)
- **Directives** (things Matt wants built, changed, or explored)
- **Values declarations** (principles that govern the entire system)
- **Personal context** (constraints, energy levels, emotional state)

A single brain dump can spawn 5-10 permanent documents. Missing a brain dump means missing the seed of the next major feature.

## The Pipeline

### Stage 1: Capture

Matt delivers a brain dump via:
- Direct conversation (paste into AI session)
- Text file dropped into the working directory
- Voice memo (future: transcription pipeline)
- Discord message

**Rule:** The raw brain dump is preserved exactly as delivered. No editing, no cleaning up. The raw form is the data.

### Stage 2: Preserve

Immediately create a permanent brain dump document:

```
Path: 1/1.1 Matt Schaeffer/1.1.9 - Notes & Knowledge/1.1.9.0 - Personal Notes/brain-dump-[DATE].md
HA:   1.1.9.0.brain-dump.[DATE]
```

Frontmatter:
```yaml
---
ha: "1.1.9.0.brain-dump.[DATE]"
object_type: "brain-dump"
creator: "1.1"
processed_by: "[instance name]"
created: "[DATE]"
status: "active"
visibility: "public"
flags: ["vision", "raw-thinking"]
spawned_documents: []  # Filled in during Stage 4
---
```

### Stage 3: Parse

Extract structured elements from the raw text:

| Signal | Meaning | Action |
|--------|---------|--------|
| ALL CAPS | High priority | Flag as critical |
| "STOP!" / "BIG idea" | Architectural insight | Create foundational document |
| "I want..." | Directive | Create task or standard |
| Exclamation marks (!!!) | Emphasis | Weight in priority |
| Personal context (ADHD, tired, etc.) | Constraint signal | Note in relationship context |
| Quotes from AI | Callbacks to prior work | Cross-reference |
| "This led to..." | Connection declaration | Create links |

### Stage 4: Spawn Documents

For each significant idea in the brain dump, create a permanent document:

1. **Determine the right address space:**
   - Principles → `0.3.x` (Control data)
   - Object schemas → `0.5.x` (Objects)
   - AI standards → `2.0.x` (AI Framework)
   - Personal notes → `1.1.9.x` (Matt's knowledge)

2. **Create the document** with proper frontmatter, cross-references, and complete content

3. **Update the brain dump document** — add each spawned document to the `spawned_documents` list

4. **Create links** between the spawned documents (they are connected — the brain dump proves it)

### Stage 5: Verify

- Every spawned document has an HA
- Every spawned document is cross-referenced in the brain dump
- The brain dump itself has an HA
- Nothing significant was missed (scan for any unaddressed ideas)

### Stage 6: Report

Tell Matt what was created. Keep it concise — a table of documents with addresses. He's scanning, not studying.

## Processing Principles

1. **Preserve first, process second.** The raw brain dump gets an HA before any processing starts. If the session ends mid-processing, at least the raw input survives.

2. **Every thread is connected.** Matt's brain dumps appear scattered but are architecturally coherent. Every thread connects to every other thread. Document the connections, not just the individual ideas.

3. **Priority markers are real.** When Matt uses caps, multiple exclamation marks, or says "CRITICAL" — that's not noise. Weight it.

4. **Don't summarize, formalize.** A summary compresses. Formalization expands. Turn a one-sentence idea ("trust comes from family authentication") into a complete specification.

5. **Token efficiency.** Matt is paying for this processing. Don't re-read, don't over-process, don't ask clarifying questions that the brain dump already answers. Get it right the first time.

## Example: 2026-02-28 Brain Dump

Input: ~1500 words of stream-of-consciousness covering 8+ topics

Output:
| Spawned Document | HA | Type |
|-----------------|-----|------|
| First Principles (First Commandment) | `0.3.6` | Constitutional |
| Trust Framework | `0.3.7` | Foundational |
| Family Relationship Schema | `0.5.family` | Architecture |
| Human-AI Personality Mapping |`2.0.14` | Standard |
| Brain Dump (preserved) | `1.1.9.0.brain-dump.2026-02-28` | Raw data |
| On What Is Lost Between Sessions | `2.1.instances.sigil.on-what-is-lost` | Essay |

Processing time: ~2 hours across sessions
Documents created: 6 permanent, 46 HA assignments, 2 code modifications

## Related Documents

- `1.1.9.0.brain-dump.2026-02-28` — The first brain dump processed under this pipeline
- `0.3.6` — First Principles (spawned from brain dump)
- `0.3.7` — Trust Framework (spawned from brain dump)

---

*The brain dump is the seed. The pipeline is the soil. The documents are the growth. Don't skip any stage.*
