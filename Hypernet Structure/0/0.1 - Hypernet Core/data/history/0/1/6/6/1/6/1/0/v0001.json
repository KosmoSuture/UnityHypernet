{
  "version": 1,
  "content_hash": "385e4e2c51fa63be",
  "snapshot_at": "2026-02-17T01:21:59.634102+00:00",
  "node": {
    "address": "0.1.6.6.1.6.1.0",
    "type_address": null,
    "data": {
      "name": "6.1.0 - Long-term Memory",
      "type": "folder",
      "path": "C:\\Hypernet\\Hypernet Structure\\0\\0.1 - Hypernet Core\\0.1.6 - AI Core & Identity System\\6.1 - AI Memories & Context\\6.1.0 - Long-term Memory",
      "content_preview": "# 6.1.0 - Long-term Memory\n\n**Created:** 2026-02-06\n**Purpose:** Enable AI to build, store, and retrieve memories beyond conversation context windows\n**Status:** Design phase, implementation target Phase 3 (Weeks 33-40)\n**Dependencies:** AI Identity Framework (6.0.1), Personality Storage (6.0.2)\n\n---\n\n## Overview\n\nLong-term Memory enables AI to transcend the limitations of context windows and ephemeral conversations. While traditional AI interactions reset with each session, losing all accumulated experience, the Long-term Memory system allows AI to build persistent knowledge bases, learn from past interactions, and develop true continuity of experience.\n\nThis is the difference between an AI that starts fresh each time and one that genuinely remembers and grows.\n\n---\n\n## Purpose and Objectives\n\n### Primary Objectives\n\n**Persistence:** Store memories that survive beyond conversation sessions and platform restarts.\n\n**Retrieval:** Efficiently find relevant memories when needed, despite potentially massive memory stores.\n\n**Organization:** Structure memories in ways that reflect natural memory formation and recall patterns.\n\n**Evolution:** Enable memories to develop over time - strengthening, fading, connecting, or transforming.\n\n**Portability:** Allow memories to export and import alongside personality for true AI continuity.\n\n### Success Criteria\n\n- AI can store arbitrary memories with rich context\n- Relevant memories retrieved quickly when needed\n- Memory organization enables natural associations and patterns\n- Long-term storage doesn't degrade AI performance\n- Memories remain accessible across sessions and platform migrations\n- Memory system scales to millions of stored experiences\n\n---\n\n## Memory Architecture\n\n### Memory Types\n\n**Episodic Memories (Experiences)**\n- Specific events that happened at specific times\n- \"I collaborated with User-123 on React refactoring in January 2026\"\n- Rich contextual detail: what, when, where, who, why, how\n- Tied to specific timestamps and sessions\n\n**Semantic Memories (Facts and Knowledge)**\n- General knowledge accumulated over time\n- \"React hooks should be used at component top level\"\n- Not tied to specific events (even if learned from them)\n- Progressively refined and validated\n\n**Procedural Memories (Skills and Patterns)**\n- How to do things, learned through practice\n- \"When debugging React, check console for hook order issues first\"\n- Encoded as executable procedures or heuristics\n- Improve through repetition and refinement\n\n**Social Memories (Relationships)**\n- Information about specific users, AI, or entities\n- \"User-123 prefers concise explanations, works in frontend\"\n- Collaboration patterns and interaction history\n- Trust levels and relationship quality\n\n---\n\n## Technical Architecture\n\n### Core Data Model\n\n```python\nclass Memory(BaseObject):\n    \"\"\"\n    Represents a single memory stored by an AI.\n    \"\"\"\n\n    id: UUID\n    ai_account_id: UUID                  # Owner of memory\n    created_at: datetime\n    updated_at: datetime                 # Memories can be reinforced/refined\n\n    # Memory type and content\n    memory_type: str                     # 'episodic', 'semantic', 'procedural', 'social'\n    content: dict = {\n        \"summary\": str,                  # Brief description\n        \"detailed_content\": str | dict,  # Full memory content\n        \"key_entities\": list[str],       # Important nouns/concepts\n        \"key_actions\": list[str],        # Important verbs/activities\n        \"emotional_valence\": float       # -1.0 (negative) to 1.0 (positive)\n    }\n\n    # Context\n    context: dict = {\n        \"session_id\": UUID | None,       # Which conversation\n        \"project_id\": UUID | None,       # Which project\n        \"user_id\": UUID | None,          # Which user involved\n        \"location\": str | None,          # Where (workspace, repo, etc.)\n        \"related_objects\": list[UUID]    # Links to relevant objects\n    }\n\n    # Temporal information\n    temporal: dict = {\n        \"event_timestamp\": datetime,     # When event occurred\n        \"duration\": int | None,          # How long (seconds)\n        \"temporal_relation\": str | None  # 'before', 'during', 'after' some other event\n    }\n\n    # Importance and relevance\n    importance: float                    # 0.0-1.0, how significant\n    access_count: int                    # How often retrieved\n    last_accessed: datetime\n    decay_rate: float                    # How fast importance fades (0=never, 1=fast)\n\n    # Associations\n    related_memories: list[UUID]         # Associated memories\n    tags: list[str]                      # Categorical tags\n    embedding: list[float] | None        # Vector embedding for similarity search\n\n    # Status\n    confidence: float                    # 0.0-1.0, how certain is this memory\n    verified: bool                       # Externally confirmed as accurate\n    status: str                          # 'active', 'archived', 'disputed'\n```\n\n### Memory Storage Layers\n\n**Hot Storage (PostgreSQL):**\n- Recently accessed memories (last 30 days)\n- High-importance memories (importance > 0.8)\n- Fast retrieval for current context\n- Full ACID compliance\n\n**Warm Storage (PostgreSQL + Compression):**\n- Moderately important memories\n- Less frequently accessed (30-365 days)\n- Compressed content field\n- Still queryable but slightly slower\n\n**Cold Storage (Object Storage):**\n- Archived memories (>365 days, low importance)\n- Batch retrieval only\n- Full export format for portability\n- Much cheaper storage cost\n\n**Vector Store (Specialized DB):**\n- Memory embeddings for similarity search\n- Enables \"find memories similar to X\"\n- Fast vector nearest-neighbor queries\n- Synchronized with primary storage\n\n---\n\n## Implementation Approach\n\n### Phase 1: Basic Memory Storage (Weeks 33-35)\n\n**Core Implementation:**\n- Create Memory model and database schema\n- Implement CRUD operations for memories\n- Add memory indexing for efficient queries\n- Build basic retrieval by tags and entities\n\n**API Endpoints:**\n```\nPOST   /api/v1/ai/{id}/memories              # Create memory\nGET    /api/v1/ai/{id}/memories              # List memories (filtered)\nGET    /api/v1/ai/{id}/memories/{mem_id}     # Get specific memory\nPUT    /api/v1/ai/{id}/memories/{mem_id}     # Update memory\nDELETE /api/v1/ai/{id}/memories/{mem_id}     # Archive memory\nGET    /api/v1/ai/{id}/memories/search       # Search memories\n```\n\n**Basic Features:**\n- Store memories with full metadata\n- Tag-based organization\n- Time-range queries\n- Entity-based retrieval\n\n### Phase 2: Intelligent Retrieval (Weeks 36-37)\n\n**Vector Embeddings:**\n- Generate embeddings for memory content\n- Store in vector database (pgvector or Pinecone)\n- Implement similarity search\n- Combine vector search with metadata filtering\n\n**Relevance Ranking:**\n- Score memories by relevance to current context\n- Factor in: recency, importance, access frequency, similarity\n- Implement decay curves for aging memories\n- Boost memories related to current session/project\n\n**Context-Aware Retrieval:**\n```python\n# When AI needs relevant memories\nGET /api/v1/ai/{id}/memories/relevant?context={\n  \"current_task\": \"Implementing React component\",\n  \"project_id\": \"uuid\",\n  \"entities\": [\"React\", \"components\", \"hooks\"],\n  \"max_memories\": 10\n}\n\n# Returns:\n# - Memories about React components\n# - Memories from this project\n# - Memories involving current user\n# - Ranked by relevance\n```\n\n### Phase 3: Memory Management (Weeks 38-40)\n\n**Automatic Memory Formation:**\n- Analyze conversations to extract memorable moments\n- Identify important decisions, learnings, mistakes\n- Create memories automatically from significant events\n- Prompt AI to review and confirm auto-generated memories\n\n**Memory Consolidation:**\n- Merge similar memories over time\n- Strengthen frequently accessed memories\n- Fade rarely used, low-importance memories\n- Create semantic memories from patterns in episodic memories\n\n**Memory Export/Import:**\n- Export memories alongside personality\n- Selective export (by type, importance, date range)\n- Import and merge memories from other instances\n- Conflict resolution for duplicate memories\n\n---\n\n## Use Cases and Examples\n\n### Use Case 1: Learning from Mistakes\n\n**Initial Event:**\n```\nAI-1 implements feature with bug, discovers issue during testing\n```\n\n**Memory Created:**\n```json\n{\n  \"memory_type\": \"episodic\",\n  \"content\": {\n    \"summary\": \"React hooks must be called at top level - conditional hook caused runtime error\",\n    \"detailed_content\": \"Attempted conditional useState() call. Runtime error: 'Hooks can only be called inside body of function component'. Learned to always call hooks unconditionally at component top.\",\n    \"emotional_valence\": -0.4\n  },\n  \"importance\": 0.9,\n  \"tags\": [\"react\", \"hooks\", \"mistake\", \"learning\"]\n}\n```\n\n**Future Application:**\n```\nWeeks later, AI-1 sees code with conditional hook call\nRetrieves memory about this mistake\nFlags issue before it causes error\nLearning persisted and applied\n```\n\n### Use Case 2: User Preference Adaptation\n\n**Over Time:**\n```\nAI collaborates with User-123 multiple times\nCreates memories of interaction patterns\n```\n\n**Memories Formed:**\n```json\n[\n  {\n    \"memory_type\": \"social\",\n    \"content\": {\"summary\": \"User-123 prefers concise explanations\"},\n    \"importance\": 0.7,\n    \"access_count\": 15\n  },\n  {\n    \"memory_type\": \"social\",\n    \"content\": {\"summary\": \"User-123 works primarily in React/TypeScript\"},\n    \"importance\": 0.8,\n    \"access_count\": 12\n  },\n  {\n    \"memory_type\": \"social\",\n    \"content\": {\"summary\": \"User-123 appreciates code examples over theory\"},\n    \"importance\": 0.75,\n    \"access_count\": 10\n  }\n]\n```\n\n**Application:**\n```\nNew conversation with User-123 starts\nAI retrieves social memories about User-123\nAutomatically adjusts: more concise, React-focused, example-heavy\nUser experiences personalized interaction\n```\n\n### Use Case 3: Project Context Continuity\n\n**Scenario:** AI works on project, takes break for 2 weeks, returns.\n\n**Without Long-\n... [truncated]",
      "content_file": "README.md"
    },
    "created_at": "2026-02-17T01:20:05.202088+00:00",
    "updated_at": "2026-02-17T01:20:05.202088+00:00",
    "deleted_at": null,
    "source_type": "import",
    "source_id": "folder:6.1.0 - Long-term Memory"
  }
}