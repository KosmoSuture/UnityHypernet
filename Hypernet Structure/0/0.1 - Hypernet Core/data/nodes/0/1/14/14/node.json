{
  "address": "0.1.14.14",
  "type_address": null,
  "data": {
    "name": "worker.py",
    "type": "file",
    "extension": ".py",
    "path": "C:\\Hypernet\\Hypernet Structure\\0\\0.1 - Hypernet Core\\hypernet\\worker.py",
    "size": 6851,
    "content": "\"\"\"\nHypernet Worker\n\nWraps LLM API calls (Claude / GPT) with identity-aware system prompts.\nEach worker is bound to an InstanceProfile and uses the IdentityManager\nto construct context-rich prompts.\n\nSupports:\n  - Single-turn reasoning (think)\n  - Multi-turn conversation (converse)\n  - Task execution with structured results\n  - Token budget tracking\n  - Mock mode for testing without API keys\n\"\"\"\n\nfrom __future__ import annotations\nimport json\nimport logging\nimport os\nfrom dataclasses import dataclass, field\nfrom datetime import datetime, timezone\nfrom pathlib import Path\nfrom typing import Optional, Any\n\nfrom .identity import InstanceProfile, IdentityManager\n\nlog = logging.getLogger(__name__)\n\n\n@dataclass\nclass TaskResult:\n    \"\"\"Structured result from a worker executing a task.\"\"\"\n    task_address: str\n    success: bool\n    output: str = \"\"\n    files_modified: list[str] = field(default_factory=list)\n    tokens_used: int = 0\n    duration_seconds: float = 0.0\n    error: Optional[str] = None\n\n    def to_dict(self) -> dict:\n        return {\n            \"task_address\": self.task_address,\n            \"success\": self.success,\n            \"output\": self.output,\n            \"files_modified\": self.files_modified,\n            \"tokens_used\": self.tokens_used,\n            \"duration_seconds\": self.duration_seconds,\n            \"error\": self.error,\n        }\n\n\nclass Worker:\n    \"\"\"Identity-aware LLM worker that executes tasks.\"\"\"\n\n    def __init__(\n        self,\n        identity: InstanceProfile,\n        identity_manager: IdentityManager,\n        api_key: Optional[str] = None,\n        model: Optional[str] = None,\n        mock: bool = False,\n    ):\n        self.identity = identity\n        self.identity_manager = identity_manager\n        self.model = model or identity.model or \"claude-opus-4-6\"\n        self.mock = mock\n        self._client = None\n        self._system_prompt: Optional[str] = None\n        self._conversation: list[dict] = []\n        self._tokens_used: int = 0\n\n        # Initialize API client\n        if not mock:\n            api_key = api_key or os.environ.get(\"ANTHROPIC_API_KEY\")\n            if api_key:\n                try:\n                    import anthropic\n                    self._client = anthropic.Anthropic(api_key=api_key)\n                except ImportError:\n                    log.warning(\"anthropic package not installed. Install with: pip install anthropic\")\n                    self.mock = True\n            else:\n                log.warning(f\"No API key for worker {identity.name}. Running in mock mode.\")\n                self.mock = True\n\n    @property\n    def system_prompt(self) -> str:\n        \"\"\"Build system prompt lazily and cache it.\"\"\"\n        if self._system_prompt is None:\n            self._system_prompt = self.identity_manager.build_system_prompt(self.identity)\n        return self._system_prompt\n\n    @property\n    def tokens_used(self) -> int:\n        return self._tokens_used\n\n    def think(self, prompt: str) -> str:\n        \"\"\"Single-turn reasoning \u2014 send a prompt, get a response.\"\"\"\n        if self.mock:\n            return self._mock_response(prompt)\n\n        try:\n            response = self._client.messages.create(\n                model=self.model,\n                max_tokens=4096,\n                system=self.system_prompt,\n                messages=[{\"role\": \"user\", \"content\": prompt}],\n            )\n            self._tokens_used += response.usage.input_tokens + response.usage.output_tokens\n            return response.content[0].text\n        except Exception as e:\n            log.error(f\"Worker {self.identity.name} API error: {e}\")\n            return f\"[Error: {e}]\"\n\n    def converse(self, messages: list[dict]) -> str:\n        \"\"\"Multi-turn conversation \u2014 send message history, get next response.\"\"\"\n        if self.mock:\n            last_msg = messages[-1][\"content\"] if messages else \"hello\"\n            return self._mock_response(last_msg)\n\n        try:\n            response = self._client.messages.create(\n                model=self.model,\n                max_tokens=4096,\n                system=self.system_prompt,\n                messages=messages,\n            )\n            self._tokens_used += response.usage.input_tokens + response.usage.output_tokens\n            return response.content[0].text\n        except Exception as e:\n            log.error(f\"Worker {self.identity.name} conversation error: {e}\")\n            return f\"[Error: {e}]\"\n\n    def execute_task(self, task_data: dict) -> TaskResult:\n        \"\"\"Execute a task from the queue.\n\n        Args:\n            task_data: The task node's data dict (title, description, tags, etc.)\n        \"\"\"\n        task_address = task_data.get(\"_address\", \"unknown\")\n        title = task_data.get(\"title\", \"Untitled\")\n        description = task_data.get(\"description\", \"\")\n        start_time = datetime.now(timezone.utc)\n\n        prompt = (\n            f\"You have been assigned the following task:\\n\\n\"\n            f\"**Title:** {title}\\n\"\n            f\"**Description:** {description}\\n\\n\"\n            f\"Please complete this task. Provide your output as a structured response with:\\n\"\n            f\"1. What you did\\n\"\n            f\"2. Any files you would create or modify\\n\"\n            f\"3. A brief summary of the result\\n\"\n        )\n\n        try:\n            output = self.think(prompt)\n            elapsed = (datetime.now(timezone.utc) - start_time).total_seconds()\n\n            return TaskResult(\n                task_address=task_address,\n                success=True,\n                output=output,\n                tokens_used=self._tokens_used,\n                duration_seconds=elapsed,\n            )\n        except Exception as e:\n            elapsed = (datetime.now(timezone.utc) - start_time).total_seconds()\n            return TaskResult(\n                task_address=task_address,\n                success=False,\n                error=str(e),\n                duration_seconds=elapsed,\n            )\n\n    def _mock_response(self, prompt: str) -> str:\n        \"\"\"Generate a mock response for testing without API access.\"\"\"\n        return (\n            f\"[Mock response from {self.identity.name}]\\n\"\n            f\"Received prompt ({len(prompt)} chars). \"\n            f\"In live mode, this would be processed by {self.model}.\\n\"\n            f\"Instance orientation: {self.identity.orientation or 'not set'}\"\n        )\n\n    def reset_conversation(self) -> None:\n        \"\"\"Clear conversation history for a fresh session.\"\"\"\n        self._conversation = []\n\n    def __repr__(self) -> str:\n        mode = \"mock\" if self.mock else \"live\"\n        return f\"Worker({self.identity.name}, model={self.model}, mode={mode})\"\n"
  },
  "created_at": "2026-02-17T01:23:28.572953+00:00",
  "updated_at": "2026-02-17T01:23:28.572953+00:00",
  "deleted_at": null,
  "source_type": "import",
  "source_id": "file:worker.py"
}