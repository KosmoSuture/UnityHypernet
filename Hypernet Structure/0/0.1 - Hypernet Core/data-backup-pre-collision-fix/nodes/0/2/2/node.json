{
  "address": "0.2.2",
  "type_address": null,
  "data": {
    "name": "0.2.1 Storage Node Specification.md",
    "type": "file",
    "extension": ".md",
    "path": "C:\\Hypernet\\Hypernet Structure\\0\\0.2 Node lists\\0.2.1 Storage Node Specification.md",
    "size": 3466,
    "content": "# 0.2.1 Storage Node Specification\n\n## Purpose\n\nStorage Nodes are the persistent memory of the Hypernet. They store encrypted Object data and participate in the global deduplication system that ensures every piece of information exists exactly once (with redundant copies for reliability).\n\n## Core Functions\n\n### 1. Object Storage\n- Store encrypted Object chunks\n- Maintain chunk metadata and checksums\n- Respond to retrieval requests\n- Verify data integrity\n\n### 2. Deduplication Participation\n- Content-addressable storage using cryptographic hashes\n- Refuse storage of duplicate chunks\n- Redirect duplicate requests to existing storage location\n\n### 3. Replication\n- Maintain required redundancy levels\n- Participate in rebalancing operations\n- Handle node failure recovery\n\n### 4. Garbage Collection\n- Track reference counts\n- Remove orphaned data (with archival)\n- Compact storage periodically\n\n## Data Model\n\n### Chunk Structure\n```yaml\nchunk:\n  chunk_id: \"[SHA-256 hash of content]\"\n  encrypted_content: \"[AES-256-GCM encrypted data]\"\n  content_size: 12345  # bytes\n  encryption_metadata:\n    key_envelope: \"[Encrypted key for authorized decryption]\"\n    nonce: \"[Encryption nonce]\"\n  replication:\n    target_copies: 3\n    current_copies: 3\n    locations: [\"node_id_1\", \"node_id_2\", \"node_id_3\"]\n  metadata:\n    created: \"2025-01-30T12:00:00Z\"\n    last_verified: \"2025-01-30T12:00:00Z\"\n    access_count: 42\n    owner_object: \"[Object address]\"\n```\n\n### Chunk Size Limits\n| Type | Minimum | Maximum | Typical |\n|------|---------|---------|---------|\n| Standard | 1 KB | 16 MB | 1 MB |\n| Large Object | Uses chunking with merkle tree | | |\n\n## Storage Operations\n\n### PUT Operation\n```\n1. Receive encrypted chunk + metadata\n2. Compute content hash\n3. Check for existing chunk (dedup)\n4. If duplicate: return existing location\n5. If new: store and register with Cerberus\n6. Initiate replication to peer nodes\n7. Return success + chunk_id\n```\n\n### GET Operation\n```\n1. Receive chunk_id + access token\n2. Verify access token with Cerberus\n3. Retrieve chunk from storage\n4. Verify integrity (checksum)\n5. Return encrypted chunk\n6. Log access for analytics\n```\n\n### DELETE Operation\n```\n1. Receive chunk_id + authorization\n2. Verify delete permission with Cerberus\n3. Decrement reference count\n4. If references = 0: mark for archival\n5. After archival period: remove from active storage\n6. Maintain audit trail\n```\n\n## Redundancy Levels\n\n| Data Type | Minimum Copies | Geographic Distribution |\n|-----------|---------------|------------------------|\n| System Critical | 7 | 3+ continents |\n| Standard | 3 | 2+ regions |\n| Archive | 2 | 1+ regions |\n| Personal/Private | User-defined | User-defined |\n\n## Performance Targets\n\n| Metric | Target |\n|--------|--------|\n| Read latency (cached) | < 10 ms |\n| Read latency (cold) | < 100 ms |\n| Write latency | < 50 ms |\n| Throughput per node | 1 Gbps |\n| Availability | 99.99% |\n\n## Economic Model\n\nStorage nodes are compensated through:\n- Storage fees (per GB per month)\n- Retrieval fees (per request)\n- Bandwidth fees (per GB transferred)\n\nCompensation is distributed via the Hypernet token system (see 0.3.5).\n\n## Related Documents\n\n- 0.2.0 Node Architecture Overview\n- 0.2.4 Node Registration Protocol\n- 0.5.0 Master Object Schema\n- 0.6.2 Object-to-Chunk Mapping\n- 0.8.1 Encryption Standards\n"
  },
  "created_at": "2026-02-15T11:54:04.304584+00:00",
  "updated_at": "2026-02-15T11:54:04.304584+00:00",
  "deleted_at": null,
  "source_type": "import",
  "source_id": "file:0.2.1 Storage Node Specification.md"
}